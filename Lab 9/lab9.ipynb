{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval (IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import sentence_transformers\n",
    "import sentence_transformers.cross_encoder.evaluation\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, InputExample # High-level sentence encoders.\n",
    "import sentence_transformers.models as models\n",
    "import sentence_transformers.losses as losses\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm # Enables progress bars\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "QUICK_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = load_dataset(\"BeIR/scidocs\", \"queries\", split=\"queries\")\n",
    "docs = load_dataset(\"BeIR/scidocs\", \"corpus\", split=\"corpus\")\n",
    "qrels = load_dataset(\"BeIR/scidocs-qrels\", delimiter=\"\\t\",split=\"test\")\n",
    "len(queries), len(docs), len(qrels), len(set(qrels[\"query-id\"])),\n",
    "len(set(qrels[\"corpus-id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, docs, qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUICK_RUN:\n",
    "\tqueries = queries.select(range(100))\n",
    "\tdocs = docs.select(range(2500))\n",
    "\tqrels = qrels.filter(lambda x: x[\"query-id\"] in queries[\"_id\"] and x[\"corpus-id\"] in docs[\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_testvalid = qrels.train_test_split(test_size=0.1, seed=1)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=1)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "train_test_valid_dataset = DatasetDict({'train': train_testvalid['train'],\n",
    "'test': test_valid['test'],\n",
    "'valid': test_valid['train']})\n",
    "train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triple_for_example(example):\n",
    "\tq = queries[queries[\"_id\"].index(example[\"query-id\"])][\"text\"]\n",
    "\td = docs[docs[\"_id\"].index(example[\"corpus-id\"])][\"title\"]\n",
    "\tr = example[\"score\"]\n",
    "\treturn q, d, r\n",
    "ex0 = get_triple_for_example(train_test_valid_dataset[\"test\"][0])\n",
    "ex1 = get_triple_for_example(train_test_valid_dataset[\"test\"][1])\n",
    "ex0, ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy import stats\n",
    "# From Huggingface Evaluate\n",
    "def label_dist(data):\n",
    "\t\"\"\"Returns the fraction of each label present in the data\"\"\"\n",
    "\tc = Counter(data)\n",
    "\tlabel_distribution = {\"labels\": [k for k in c.keys()], \"fractions\":[f / len(data) for f in c.values()]}\n",
    "\tif isinstance(data[0], str):\n",
    "\t\tlabel2id = {label: id for id, label in enumerate(label_distribution[\"labels\"])}\n",
    "\t\tdata = [label2id[d] for d in data]\n",
    "\tskew = stats.skew(data)\n",
    "\treturn {\"label_distribution\": label_distribution, \"label_skew\": skew}\n",
    "label_dist(data=train_test_valid_dataset[\"train\"][\"score\"]),\n",
    "label_dist(data=train_test_valid_dataset[\"valid\"][\"score\"]),\n",
    "label_dist(data=train_test_valid_dataset[\"test\"][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.map(lambda x: {\"title_text\": x[\"title\"] + \": \" + x[\"text\"]})[\"title_text\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import plotly\n",
    "\n",
    "docs_for_analysis = docs.map(lambda x: {\"title_text\": x[\"title\"] + \": \"+ x[\"text\"]})[\"title_text\"]\n",
    "topic_model = BERTopic(embedding_model=model_name,\n",
    "ctfidf_model=ClassTfidfTransformer(reduce_frequent_words=True))\n",
    "topic_model.fit(docs_for_analysis)\n",
    "topic_model.get_topic_info().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.reduce_topics(docs_for_analysis, nr_topics=15)\n",
    "fig = topic_model.visualize_documents(docs_for_analysis)\n",
    "plotly.offline.plot(fig, filename='bertopic_doc_embeddings.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='bertopic_doc_embeddings.html', width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ex_model = AutoModel.from_pretrained(model_name)\n",
    "ex_model_with_head = AutoModelForSequenceClassification.from_pretrained(model_name) # Needsfine-tuning, here for demonstration\n",
    "test_sentences = [\"This is the first sentence with complex tokens, such as SentenceTransformers.\", \"We can batch multiple sentences.\"]\n",
    "ex_tokenized = ex_tokenizer(test_sentences, return_tensors=\"pt\", padding=True, truncation=True) # Collates data with padding\n",
    "ex_res = ex_model(**ex_tokenized)\n",
    "ex_res_with_head = ex_model_with_head(**ex_tokenized)\n",
    "print(\"\\nTokenized text:\") # Word Piece Tokenization\n",
    "print(ex_tokenizer.tokenize(test_sentences))\n",
    "print(\"\\nToken IDs:\")\n",
    "print(ex_tokenized)\n",
    "print(\"\\nOutput Dictionary:\")\n",
    "print(ex_res.keys())\n",
    "print(\"\\nOutput Size:\")\n",
    "print(ex_res.last_hidden_state.size())\n",
    "print(\"\\nContextualized Token Embeddings (truncated):\")\n",
    "print(ex_res.last_hidden_state[:, :3, :7]) # First 3 tokens\n",
    "print(\"\\nPooled Embeddings (truncated):\")\n",
    "print(ex_res.pooler_output.shape, ex_res.pooler_output[:, :7])\n",
    "print(\"\\nPredicted Values (not fine-tuning)\")\n",
    "print(ex_res_with_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.embedding_model.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.embedding_model.embedding_model[0]._modules[\"auto_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class IRDataset(Dataset):\n",
    "\tdef __init__(self, queries_ds, docs_ds, qrel_ds, mode=\"cross\"):\n",
    "\t\tself.mode = mode\n",
    "\t\tqrels = defaultdict(set)\n",
    "\t\tdef transform(x):\n",
    "\t\t\tq, d, r = x[\"query-id\"], x[\"corpus-id\"], x[\"score\"]\n",
    "\t\t\tq_idx = queries_ds[\"_id\"].index(q)\n",
    "\t\t\tx[\"query_text\"] = queries_ds[q_idx][\"text\"]\n",
    "\t\t\td_idx = docs_ds[\"_id\"].index(d)\n",
    "\t\t\tx[\"doc_content\"] = docs_ds[d_idx][\"title\"] + \": \" +docs_ds[d_idx][\"text\"]\n",
    "\t\t\tx[\"label\"] = float(r)\n",
    "\t\t\tif r:\n",
    "\t\t\t\tqrels[q].add(d)\n",
    "\t\t\treturn x\n",
    "\t\tqrel_ds = qrel_ds.map(transform)\n",
    "\t\tself.q_ids = qrel_ds[\"query-id\"]\n",
    "\t\tself.d_ids = qrel_ds[\"corpus-id\"]\n",
    "\t\tself.qrels = qrels\n",
    "\t\tself.queries = qrel_ds[\"query_text\"]\n",
    "\t\tself.docs = qrel_ds[\"doc_content\"]\n",
    "\t\tself.labels = qrel_ds[\"label\"]\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tqs = self.queries[idx]\n",
    "\t\tds = self.docs[idx]\n",
    "\t\tif self.mode == \"rep\":\n",
    "\t\t\tif type(idx) is int:\n",
    "\t\t\t\ttext_list = [{\"query\": qs}, {\"doc\": ds}]\n",
    "\t\t\telse:\n",
    "\t\t\t\ttext_list = [[{\"query\": q} for q in qs], [{\"doc\": d}for d in ds]]\n",
    "\t\t\t\treturn InputExample(texts=text_list,label=self.labels[idx])\n",
    "\t\treturn InputExample(texts=[qs, ds], label=self.labels[idx])\n",
    "\tdef set_mode(self, mode):\n",
    "\t\tself.mode = mode\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = IRDataset(queries, docs, train_test_valid_dataset[\"train\"])\n",
    "valid_ds = IRDataset(queries, docs, train_test_valid_dataset[\"valid\"])\n",
    "train_ds[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoBERT = CrossEncoder(\n",
    "    model_name, \n",
    "\tnum_labels=1, # Perform binary classification\n",
    "\tdevice=\"mps\", # Will use CUDA if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoBERT.predict([ex0[:2], ex1[:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32)\n",
    "# We need sentence pairs format for the library here.\n",
    "# valid_dl = DataLoader(valid_ds, batch_size=32)\n",
    "sentence_pairs = list(zip(valid_ds.queries, valid_ds.docs))\n",
    "labels = valid_ds.labels\n",
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoBERT.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_evaluator = sentence_transformers.cross_encoder.evaluation.CEBinaryClassificationEvaluator(sentence_pairs, labels, show_progress_bar=True)\n",
    "monoBERT.fit(train_dataloader=train_dl,\n",
    "\tloss_fct=None, # uses nn.BCEWithLogitsLoss()\n",
    "\tevaluator=class_evaluator,\n",
    "\tepochs=10,\n",
    "\toptimizer_class=torch.optim.AdamW,\n",
    "\tshow_progress_bar=True,\n",
    "\tsave_best_model=True,\n",
    "\toutput_path=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoBERT.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoBERT.predict([ex0[:2], ex1[:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File not provided for the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CEBinaryClassificationEvaluator_results.csv\")\n",
    "df.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"epoch\").drop(columns=[\"steps\"]).plot()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repBased = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs, ds = repBased.encode([{\"query\": ex0[0]}, {\"query\": ex1[0]}]),\n",
    "repBased.encode([{\"doc\": ex0[1]}, {\"doc\": ex1[0]}])\n",
    "sentence_transformers.util.cos_sim(qs, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_mode(\"rep\")\n",
    "valid_ds.set_mode(\"rep\")\n",
    "train_dl_repBased = DataLoader(train_ds, batch_size=32,\n",
    "collate_fn=repBased.smart_batching_collate)\n",
    "valid_dl_repBased = DataLoader(valid_ds, batch_size=32,\n",
    "collate_fn=repBased.smart_batching_collate)\n",
    "assert next(iter(train_dl_repBased))\n",
    "queries_dict = dict(zip(valid_ds.q_ids, valid_ds.queries))\n",
    "docs_dict = dict(zip(valid_ds.d_ids, valid_ds.docs))\n",
    "qrels_dict = valid_ds.qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_evaluator = sentence_transformers.evaluation.InformationRetrievalEvaluator(queries_dict, docs_dict, qrels_dict, write_csv=True)\n",
    "repBased.fit(\n",
    "    train_objectives=[(train_dl_repBased,losses.CosineSimilarityLoss(repBased))],\n",
    "\tevaluator=ir_evaluator,\n",
    "\tepochs=10,\n",
    "\toptimizer_class=torch.optim.AdamW,\n",
    "\tshow_progress_bar=True,\n",
    "\tsave_best_model=True,\n",
    "\toutput_path=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs, ds = repBased.encode([{\"query\": ex0[0]}, {\"query\": ex1[0]}]),\n",
    "repBased.encode([{\"doc\": ex0[1]}, {\"doc\": ex1[0]}])\n",
    "sentence_transformers.util.cos_sim(qs, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eval/Information-Retrieval_evaluation_results.csv\")\n",
    "df.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"epoch\").drop(columns=[\"steps\"]).plot(legend=False)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# API configuration\n",
    "client = OpenAI(\n",
    "\tapi_key=os.environ['OPENAI_API_KEY'],\n",
    ")\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERP_API_KEY\"] = os.getenv(\"SERP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "\tmodel=\"text-davinci-003\",\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=256,\n",
    "\ttop_p=1,\n",
    "\tfrequency_penalty=0,\n",
    "\tpresence_penalty=0,\n",
    "):\n",
    "\t\"\"\" set openai parameters\"\"\"\n",
    "\topenai_params = {}\n",
    "\topenai_params['model'] = model\n",
    "\topenai_params['temperature'] = temperature\n",
    "\topenai_params['max_tokens'] = max_tokens\n",
    "\topenai_params['top_p'] = top_p\n",
    "\topenai_params['frequency_penalty'] = frequency_penalty\n",
    "\topenai_params['presence_penalty'] = presence_penalty\n",
    "\treturn openai_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(params, prompt):\n",
    "\t\"\"\" GET completion from openai api\"\"\"\n",
    "\tresponse = openai.Completion.create(\n",
    "\tengine = params['model'],\n",
    "\tprompt = prompt,\n",
    "\ttemperature = params['temperature'],\n",
    "\tmax_tokens = params['max_tokens'],\n",
    "\ttop_p = params['top_p'],\n",
    "\tfrequency_penalty = params['frequency_penalty'],\n",
    "\tpresence_penalty = params['presence_penalty'],\n",
    "\t)\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab 9/lab9.ipynb Cell 44\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m params \u001b[39m=\u001b[39m set_open_params()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe sky is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m response \u001b[39m=\u001b[39m get_completion(params, prompt)\n",
      "\u001b[1;32m/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab 9/lab9.ipynb Cell 44\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion\u001b[39m(params, prompt):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\" GET completion from openai api\"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \tresponse \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \tengine \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \tprompt \u001b[39m=\u001b[39;49m prompt,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \ttemperature \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \tmax_tokens \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \ttop_p \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \tfrequency_penalty \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \tpresence_penalty \u001b[39m=\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shreyasv/Desktop/NLP/CS-F429-NLP/Lab%209/lab9.ipynb#X61sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/NLP/CS-F429-NLP/.venv/lib/python3.10/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_args: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "params = set_open_params()\n",
    "prompt = \"The sky is\"\n",
    "response = get_completion(params, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
